主机直接连接存储并执行用户应用程序任务

MapReduce paradigm

HDFS is the file system component of Hadoop

metadata and application data separately

metadata NameNode

application data  DataNode

 do not use data protection



NameNode

命名空间是文件 目录的层次结构，文件目录由inode记录，记录权限、修改和访问时间、命名空间和磁盘空间配额

命名空间在内存中

image：inode信息 block信息

checkpoints：持续记录image

journal：image log 



DataNodes

block代表两个文件，数据本身和元数据（校验和 代戳）

DN启动向NN handshake 注册，检查 命名空间id，软件版本

DN 永久id stroage id，第一次注册分配

发送block report

定期heartbeat给NN 确认存活

DN 发送 block report 给NN告诉他有block replicas

block report包含id generation stamp the length for each block

第一个 report 注册后马上发送，接下来的report每小时发送，提供最新视图

发送 heartbeats 给NN 确认DN正在控制，存活，默认三秒一次。十分钟没有heartbeats，考虑去掉。

heartbeats携带总共存储能力，当前存储量，数据传输量。NN利用这个安排空间 加载平衡

NN不直接call DN，用heatbeats发送指令。包含 复制给其他节点，移动本地复制，重新注册，关机，发送report

完整性，heartbeats频繁很关键，NN处理上千heartbeats每秒 除与其他NN交流，



客户机

code library 从hdfs系统导出的接口。

提供操作去读 写 删除，创造删除目录。

用户通过命名空间的路径引导文件 目录

不需要知道服务器

客户端让NN提供DN主机复制，直接找DN，要求传输。

如果要求写，先要求NN选择DN，客户机建立pipeline从点到点，第一个block写满，请求新DN，新pipeline建立

客户端可以根据DN位置优化，可以定义拷贝数量



image：元数据将应用数据描述作为目录和文件，写入磁盘的永久记录叫做checkpoint。

journal：写前的log ，持久的。改变记录在journal，不会被NN改变，一个新checkpoint建立，它会被完全替换。

NN重启时，初始化image从checkpoints，重新演示变化从journal到image更新到最后一次状态。一个新checkpoints 和空journal写回目录

checkpoints 或者 journal丢失损坏，命名空间信息部分或完全丢失。为了保护关键信息，系统保存checkpoints journal多个地方。推荐目录存在不同卷，一个存储目录存在远程NFS服务器。NN自动关闭如果没有storage 目录

NN多线程，同时处理多个客户。保存到磁盘时瓶颈。需要等待其中之一刷新同步。所有同时处理的事务会一起提交



checkpointNode 

可选

CN 周期建立Checkpoints journal，与NN不在一个机，节省内存。下载checkpoints journal 从NN定期，合并，返回新checkpoints给NN

周期创建checkpoints可以保护系统元数据。



BackupNode备份

可以创造checkpoints，维护image与NN同步

接受journal从NN，NN对待BN作为journal存储

创造checkpoints不用大量下载，只读NN，保存元数据除了block位置。



文件系统的快照

可选

最小化潜在危险在更新数据

快照机制让管理员持续保存当前状态。可以回滚到快照时

快照创建（只有一个）当系统开始。NN第一次读checkpoints，journal，合并他们在内存，然后NN写新checkpoints journal

handshake时，NN指导DN是否创建新快照。

DN创建storage 目录的拷贝 硬链接 已存在的文件

DN删除block，只移除硬链接，并且对块的修改使用写时复制

NN可以根据快照回滚，NN恢复checkpoints，DN后台删除block。无法前滚

布局版本数据格式，持续存在NN DN 目录。启动时强制转换布局版本。NN，DN版本不是分开的



IO

应用程序创建新file写数据，file关闭，字节不能被更改移除，除非新数据增加。

单写，多读模型

应用写文件需要获得租用，其他应用无法写

写客户端发送heartbeat给NN，周期更新租期

soft limit（时间长），其他可以抢占。hard limit （时间短，

不保证数据对读者可见 直到文件关闭

hflush可以保证。当前包直接发送pipeline，hflush等到DN承认包成功传递。数据在hflush后写入

![image-20210531163142713](https://gitee.com/csjuesz/image/raw/master/20210531163149.png)

第二个包裹携带hflush

每个file都有checksum，客户端检验校验和。DN分开存校验和。传输file和checksum

如果读失败，可以选择下一DN

读一个在写的文件，NN先确定最新长度

HDFS IO适合脚本处理系统 MapReduce，需要高并发读写

也需要提高读写相应时间，支持Scribe 提供实时数据



block摆放

放在多个架子，一个架子一个交换机

同架子的节点通信要比不同的快

hdfs估计带宽靠二者距离，二者距离公共祖先的距离

允许配置脚本获得节点架子号

DN注册，NN用脚本决定哪个架子。如果没有这个脚本，所有节点都是一个架子

复制的摆放是hdfs数据可靠性 读写性能的关键

默认摆放 权衡最小写代价，最大可靠性，可用性，总计读带宽。

新节点创建 hdfs将第一个复制摆放在writer，第二第三在不同架子，其余随机（不在同一节点，尽量不在一个架子。

目标节点选定后，节点组成管道线到第一个复制，数据按照这个顺序。

这个规则减少架子间 节点间通信

总结

1. DN不存多个复制
2. 没有架子存两个相同的节点，如果有多的架子



（有的地方写的好像是放两个架子



副本管理

维持副本数量恒定

复制优先队列



平衡器

设定一个阈值，检查DN 使用量与总体使用量

最小化架子间移动



Block Scanner

周期扫描复制 验证checksum

验证时间 存在 一个人类可读的log

任意时间只有两个log 当前 之前

提醒NN。当新数据当来 才删除



退役

可以登记非持久

逐渐转移，不存新的



DistCp 

数据转移 MapReduce工作